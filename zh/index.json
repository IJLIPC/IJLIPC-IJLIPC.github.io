[{"authors":["admin"],"categories":null,"content":"智能感知与控制国际联合实验室 ​\t该实验室由美国华盛顿大学（西雅图）、上海工程技术大学、浙江捷尚视觉科技股份有限公司联合成立。以“世界一流大学+上海工程技术大学+知名企业”为队伍，立足“科学、技术、工程协同创新”的运行机制，为聚一流师资、育一流人才、创一流学科提供国际化高水平学科平台。实验室主要研究列举如下：\n1. 人脸识别、性别识别、年龄分析、表情分析\n人脸识别，是基于人的脸部特征信息进行身份识别的一种生物识别技术。用摄像机或摄像头采集含有人脸的图像或视频流，并自动在图像中检测和跟踪人脸，进而对检测到的人脸进行脸部识别的一系列相关技术，通常也叫做人像识别、面部识别。本项目就是根据提前导入的个人照片数据库，在快速检测到人脸的基础上实现人脸最佳匹配，实现人脸识别。\n本项目还可以根据检测到的人脸预测性别和年龄，比如现在很多手机相机都有脸部识别并能显示年龄与性别信息，同时，该项目还可以用来判断人脸部的表情信息，判断一个人的喜怒哀乐，人脸识别技术现在已经开始应用于车站的安监系统、高校的门禁系统、公司的考勤系统等。\n随着移动互联网的崛起，一些人脸识别技术的开发者将该项技术应用到娱乐领域中，如应用开心明星脸等，根据人脸的轮廓，肤色，纹理，质地，色彩，光照等特征来计算照片中主人公与明星的相似度。在不久的将来，人脸识别还可以应用于测谎系统，比如，中国的云从科技已经研发出基于人脸识别的人工智能测谎仪。相信人脸识别技术会越走越远。\n​ 2. 跨相机网络的行人跟踪与重识别\n跨相机网络的行人跟踪与重识别又称行人重识别，是利用计算机视觉技术判断图像或者视频序列中是否存在特定行人的技术，主要是给定一个监控行人图像，然后检索跨设备下的该行人图像。\n研究难点：\n（1）图像比较模糊并且广泛存在后脑勺和侧脸的情况，因此无法进行人脸识别，（2）摄像头之间有色差并受到光照的影响所以仅靠衣服颜色无法做出精确的判断，（3）容易出现撞衫情况但是研究方法普遍忽略图像细节\n研究方法：\n在得到的数据集中的训练集上进行模型的训练，得到模型后对图片提取特征计算相似度。\n常用的研究方法\n（1）基于部件匹配的方法\n根据人体的结构信息对图像进行分割，然后按部件来进行匹配。\n（2）基于损失函数的方法\n基于高层语义信息，设置一些辅助任务，帮助模型学习到好的特征表达。\n​ 3. 区域客流密度+区域客流统计\n客流统计是一项重要的市场研究手段，能够为公共、商业系统的运营决策和综合管理提供准确及时的数据参考，对公共安全、科学决策起到非常重要的作用。适用在商业、连锁、公园和景区、铁路、机场、博物馆、展览馆等众多运营场所。\n客流量是代表着某个区域的人气价值指标，人群密度多有好有坏，只有在可控制的范围内才不会造成隐患。\n客流统计的应用、实现人群密度检测的效果，主要利用当前先进的机器视觉，计算机图像视频分析技术，模式识别技术、人工智能机器学习、深度学习技术，侦测预设区域内移动人群密度、拥挤度、实时显示区域内人群的数量。或者拥挤程度百分比，如果密度超过预设值，系统就会发出警报。\n客流量统计安装检测人群效果：\n多个区域设备的安装、如出入口、柜台、店铺、楼道通道等等设置多个防区检测人员密度。\n能在一个防区或多个防区设置多种分析功能。\n能实时分析检测每一个防区的人群密度价值及拥挤度百分比。\n人群检测密度价值：\n主动监测区域人密度、拥挤程度。\n提高公共安全，合理引导人流。\n客流统计人群密度检测是为了提升客流量的价值，同时也是为了降低拥挤和低对比度环境中的安全隐患，提升安全等级以及对灾难隐患的预见和主动性\n​ 4. 打架监控应用\n一种视频中打架的侦测方法，包括如下步骤:\n(1)有效特征点值获取:进行特征点检测，特征点运动估计和量化；\n(2)剧烈运动块获取:将图像分块，统计每块特点方向直方图，计算直方图熵值，如果直方图熵值超过一定阈值就认为是剧烈运动块；\n(3)累计剧烈运动分数:当某帧某块是剧烈运动块时，其剧烈运动分数加一定值；如果不是，就将此块剧烈运动分数缩减一定比例；\n(4)剧烈运动连通区域输出:若某块剧烈可信值超过设定阈值，就认为是剧烈运动块，并将连通的剧烈运动块组成连通区域，如果连通区域面积大于设定阈值，就作为剧烈运动连通区域输出。\n打架监控主要可以应用于：监狱打架斗殴监控、无人监管场所或人流量大的公共场所（如：车站、酒店、宾馆、商场等公共场所）打架监控。\n​ ​ 个体打架 群体打架\n5. 实验室智能行为分析\n行为识别是指通过分析视频、深度传感器等数据，利用特定的算法，对行人的行为进行识别、分析的技术。这项技术被广泛应用在视频分类、人机交互、安防监控等领域。行为识别包含两个研究方向：个体行为识别与群体行为（事件）识别。\n行为分析主要实现以下检测\n（1）警戒区检测\n对于重点区域，为防止人员或车辆进入，可以设置安全区域设别来检测是否有人、物体或车辆进入预定区域；支持区域范围的自定义设置，可以是任意形状、大小矩形或者不规则多边形；以设置虚拟区域范围方式进行监测，保护某些不允许别人进入的禁区，有人、车辆或者物体进入或者离开某一个特定区域时，系统会产生报警通知值班人员。\n（2）人数统计\n人数统计分析基于对运动目标的智能跟踪与识别技术，通过对区域或方向的设定来统计通过人数，以及人群流动量、人群流动方向的统计及分析数据。\n（3）打架检测\n通过对视频监控下相关人员的运动特征、运动轨迹、肢体剧烈变化的自动识别，实时检测是否有打架斗殴事件，以防事件的进一步恶化。\n（4）脱岗检测\n对于重要场所，通常有值班人员，为防止突发异外事件发生，要求值班区域必须有人值守，为防止脱岗现象发生，可通过脱岗检测方式，实现对设定区域区的人员检测。典型应用如哨兵站岗、监所监控中心、重点单位门卫室等。\n​ 6. 非侵入式FFR测量技术\n目前针对血管堵塞诊断，仍旧完全依赖于医生的主观意识完成。临床上缺乏一种对血管狭窄度、堵塞程度等进行分析的辅助诊断工具。我们的作品应用冠状动脉血管堵塞辅助诊断技术，即将人工智能技术应用于辅助诊断诊疗中，让计算机“学习”专家医生的医疗知识，模拟医生的思维和诊断推理，从而给出可靠诊断和治疗方案，从而极大地降低医生的工作量，该技术可以大量扩展到乡镇，提高基层医疗水平，减少医生对病人的误诊率，通过辅助诊断技术，解决血管堵塞年轻化问题，做到及时预防、及时治疗。\n使用传统算法和深度学习相结合的方法对患者CT图像进行血管 分割，我们所采用的U-Net网络在分割图像方面也是起到了很好的效果；分割完 成后对血管结构进行三维重建，通过得到的 3D 血管模型图来得到血管直径，最 后计算出冠状动脉血流储备分数来判断血管的狭窄度、堵塞程度，从而完成冠状 动脉血管堵塞程度的自动分析。\n（1）融合冠脉CTA与FFR的优势。对患者无创伤，费用低\n（2）采用传统算法与深度学习结合，血管图分割精度高\n（3）采用机器学习方法计算FFR值，速度快，精度高\n​ ​ 算法流程\n​ ​ 作品展示\n7. 胃癌诊断研究计划\n基于深度学习的人工智能技术在胃癌诊断中的应用目的在于构建和验证一个用于早期胃癌自动识别的深度学习模型，提高早期胃癌的识别和诊断水平。\n（1）多特征融合的胃癌分期诊断\n胃癌与淋巴结的大小与位置等特征是胃癌分期重要的参考。\n▪通过深度学习来学习潜在的胃癌和淋巴结特征。\n▪通过联合贝叶斯算法将学习到的胃癌特征、胃癌与淋巴结的大小融合，从而诊断胃癌的分期。\n（2）胃癌手术安全性评估\n▪通过MPR多平面重建技术将三维重建投影到多个不同视角下，融合各视角下的特征，综合分析得出血管的变异类型。\n▪通过多层三维卷积层与两层全连接层判断淋巴结与血管是否缠绕，为胃癌手术提供重要的指导意见。\n（3）总体技术方案\n基于深度学习的精细粒度分割等人工智能技术的引入，将有望使中国智能胃癌诊疗技术达到国际领先水平，在胃癌研发领域，开发具有临床实际价值的病理切片智能识别、智能放疗等技术，可有效提高早期胃癌的诊断率、进展期胃癌的控制率。\n​ 8. 掌静脉识别\n在近红外光的照射下，获取静脉血管形状的图像。经过特征提取，最后进行特征匹配和对比匹配结果，实现身份鉴别。\n项目的过程：分为3个阶段：\n1.图像的采集：手掌在720 ～ 1100 nm近红外光的照射下，由于静脉血管中的血色素比周围其他生物组织吸收更多的近红外辐射，手掌反射回的光被图像传感器接收，形成静脉血管的血管形状图像。\n2.图像预处理：数字化和图像增强、图像去噪等一系列操作。\n3.特征提取及匹配：根据特征提取方法不同，现有的掌脉识别方法，可归结为以下几类: 基于结构特征、基于纹理特征和基于子空间的方法。\n应用：掌静脉识别可被广泛应用在考勤，系统、门禁系统、银行、电子商务身份认证、机密信息存取控制等众多应用中。\n实用性：具有较强的普遍性和唯一性；使用程度广；用户接受度好；很难伪造和模仿；识别率较高；只有活体才能识别。\n​ 9. 驾驶员动作识别\n本项目通过拍摄驾驶员的行车视频，运用机器视觉技术对驾驶员的行为进行分析检测，从而判断驾驶员在行车过程中是否存在违规行为。\n项目的过程：\n图像预处理：由于在实际应用中会受到环境影响（如受到的光照影响），因此进行检测前需要先对图片进行预处理（如：滤波、图像增强等），减少外界因素对检测结果的干扰和影响。\n感兴趣区域的建立：运用边缘检测和椭圆检测，完成包含驾驶员主要肢体部位的感兴趣区域的建立。\n肤色特征识别：对颜色空间进行选择，并在确定颜色空间后，完成一些特征的提取，建立肤色模型，对脸部手部所在位置进行确定。\n驾驶行为分类：可以使用贝叶斯分类算法对驾驶员行为进行分类。\n对驾驶行为分类方法进行验证。\n应用：该项技术被应用于实时的驾驶监控，提升车辆行驶安全。\n实用性：获得信息的途径简单，对人和车造成的影响较小，具有非接触性的优点。\n​ ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://IJLIPC.github.io/zh/author/%E6%99%BA%E8%83%BD%E6%84%9F%E7%9F%A5%E4%B8%8E%E6%8E%A7%E5%88%B6%E5%9B%BD%E9%99%85%E8%81%94%E5%90%88%E5%AE%9E%E9%AA%8C%E5%AE%A4/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E6%99%BA%E8%83%BD%E6%84%9F%E7%9F%A5%E4%B8%8E%E6%8E%A7%E5%88%B6%E5%9B%BD%E9%99%85%E8%81%94%E5%90%88%E5%AE%9E%E9%AA%8C%E5%AE%A4/","section":"authors","summary":"智能感知与控制国际联合实验室 ​\t该实验室由美国华盛顿大学（西雅图）、上海工程技术大学、浙江捷尚视觉科技股份有限公司联合成立。以“世界一流大学+上海工程技术大学+知名企业”为队伍，立足“科学、技术、工程协同创新”的运行机制，为聚一流师资、育一流人才、创一流学科提供国际化高水平学科平台。实验室主要研究列举如下：\n1. 人脸识别、性别识别、年龄分析、表情分析\n人脸识别，是基于人的脸部特征信息进行身份识别的一种生物识别技术。用摄像机或摄像头采集含有人脸的图像或视频流，并自动在图像中检测和跟踪人脸，进而对检测到的人脸进行脸部识别的一系列相关技术，通常也叫做人像识别、面部识别。本项目就是根据提前导入的个人照片数据库，在快速检测到人脸的基础上实现人脸最佳匹配，实现人脸识别。\n本项目还可以根据检测到的人脸预测性别和年龄，比如现在很多手机相机都有脸部识别并能显示年龄与性别信息，同时，该项目还可以用来判断人脸部的表情信息，判断一个人的喜怒哀乐，人脸识别技术现在已经开始应用于车站的安监系统、高校的门禁系统、公司的考勤系统等。\n随着移动互联网的崛起，一些人脸识别技术的开发者将该项技术应用到娱乐领域中，如应用开心明星脸等，根据人脸的轮廓，肤色，纹理，质地，色彩，光照等特征来计算照片中主人公与明星的相似度。在不久的将来，人脸识别还可以应用于测谎系统，比如，中国的云从科技已经研发出基于人脸识别的人工智能测谎仪。相信人脸识别技术会越走越远。\n​ 2. 跨相机网络的行人跟踪与重识别\n跨相机网络的行人跟踪与重识别又称行人重识别，是利用计算机视觉技术判断图像或者视频序列中是否存在特定行人的技术，主要是给定一个监控行人图像，然后检索跨设备下的该行人图像。\n研究难点：\n（1）图像比较模糊并且广泛存在后脑勺和侧脸的情况，因此无法进行人脸识别，（2）摄像头之间有色差并受到光照的影响所以仅靠衣服颜色无法做出精确的判断，（3）容易出现撞衫情况但是研究方法普遍忽略图像细节\n研究方法：\n在得到的数据集中的训练集上进行模型的训练，得到模型后对图片提取特征计算相似度。\n常用的研究方法\n（1）基于部件匹配的方法\n根据人体的结构信息对图像进行分割，然后按部件来进行匹配。\n（2）基于损失函数的方法\n基于高层语义信息，设置一些辅助任务，帮助模型学习到好的特征表达。\n​ 3. 区域客流密度+区域客流统计\n客流统计是一项重要的市场研究手段，能够为公共、商业系统的运营决策和综合管理提供准确及时的数据参考，对公共安全、科学决策起到非常重要的作用。适用在商业、连锁、公园和景区、铁路、机场、博物馆、展览馆等众多运营场所。\n客流量是代表着某个区域的人气价值指标，人群密度多有好有坏，只有在可控制的范围内才不会造成隐患。\n客流统计的应用、实现人群密度检测的效果，主要利用当前先进的机器视觉，计算机图像视频分析技术，模式识别技术、人工智能机器学习、深度学习技术，侦测预设区域内移动人群密度、拥挤度、实时显示区域内人群的数量。或者拥挤程度百分比，如果密度超过预设值，系统就会发出警报。\n客流量统计安装检测人群效果：\n多个区域设备的安装、如出入口、柜台、店铺、楼道通道等等设置多个防区检测人员密度。\n能在一个防区或多个防区设置多种分析功能。","tags":null,"title":"智能感知与控制国际联合实验室","type":"authors"},{"authors":[],"categories":[],"content":"主要项目成果 ​\t团队注重与各行业企业开展产学研合作，以IEEE+及AI+为基本模式，广泛服务社会与产业需求，多项成果已得到成功应用。主要成果如下：\n1.非侵入式FFR测量技术\u0026mdash;与上海市中山医院合作 ​\t目前针对血管堵塞诊断，仍旧完全依赖于医生的主观意识完成。临床上缺乏一种对血管狭窄度、堵塞程度等进行分析的辅助诊断工具。我们的作品应用冠状动脉血管堵塞辅助诊断技术，即将人工智能技术应用于辅助诊断诊疗中，让计算机“学习”专家医生的医疗知识，模拟医生的思维和诊断推理，从而给出可靠诊断和治疗方案，从而极大地降低医生的工作量。\n2.胃癌分期诊断研究项目\u0026mdash;与上海市长征医院合作 ​\t中国是一个胃癌发病和死亡高发的国家。从发病率来看，仅次于肝癌，位居第二位。由于中国的人口基数非常大，目前胃癌发病总人数占全世界约47%，即将近一半的胃癌病人在中国。究其原因一是我国早期胃癌的检出率低，二是诊治流程的规范化程度低，三是胃癌手术操作的规范化程度尚未在基层医院建立。首诊医生对胃癌患者的处理，将直接影响患者的预后。决定医生制订治疗方案的最重要一环，就是医生对患者的胃癌术前分期判断，因为只要分期判断准确，结合NCCN指南和胃癌专家共识中国版，就可以按图索骥地给出合理的治疗方案。胃癌与淋巴结的大小与位置等特征是胃癌分期重要的参考。\r基于深度学习的人工智能技术在胃癌诊断中的应用目的在于构建和验证一个用于早期胃癌自动识别的深度学习模型，提高早期胃癌的识别和诊断水平。\n3.基于三维眼震检测的眩晕智能诊断系统\u0026mdash;与复旦大学附属眼耳鼻喉科医院合作及上海志听医疗科技有限公司 ​\t在前庭功能检查器械领域，主流前庭功能检查技术皆依托检查不同条件下眼球的移动情况进而推断受试者的前庭功能，其主要检查功能为前庭眼反射，也是外周前庭在保持平衡过程中最为重要的功能。代表的检查有视频眼动电图、甩头试验、前庭自旋转检查以及良性阵发性位置性眩晕（BPPV，俗称耳石症）的动态位置试验等，其中最为特殊的是BPPV的检查：在早期无器械辅助情况下，医生在床旁进行动态位置试验，将受试者身体和头部摆至检查或治疗的体位，通过肉眼观察受试者眼球运动情况判断病情。手法检查与复位容易受诸多因素制约影响检查或治疗效果；例如患者睁眼看见周围物体后眩晕感会更加强烈，实践中常常因患者难以睁眼不能观察到患者的眼球运动，此外，许多患有颈椎疾病或腰椎疾病患者无法配合一些幅度大的检查或治疗动作，使诊疗无法顺利进行。本项目基于大数据的深度学习算法提取足够的BPPV眼震特征，对主要几种类型（水平半规管管石型BPPV，后半规管BPPV等）的BPPV进行有效识别和分型，指导基层医院对BPPV进行科学合理的诊治。其特色和创新点：（1）摆脱传统BPPV医生个人经验性诊疗的方式，首次提出以数据形式为BPPV诊疗提供最为客观的证据。（2）结合三维眼震（水平、垂直方向结合扭转方向眼震）与转椅位置多种参数加入BPPV诊疗分析。（3）基于大量实际病例与临床一线医生权威诊断资料的大数据分析。（4）国内乃至全世界唯一同时拥有能满足智能诊疗数据搜集需求的BPPV诊疗硬件与软件：能自由控制速度加速度和能摆动精准体位的诊疗转椅，以及能1080p高清条件记录眼球运动的红外眼罩，结合能实时记录与分析瞳孔二维位置的软件系统，手机端可记录眼震和陀螺仪同步位置的Verti-Mobile app。\n4.基于无人机的智能缺陷检测系统\u0026mdash;与中国商飞上海飞机制造有限公司合作 ​\t无人机自动巡航，研究融合 UWB无线定位、视觉定位和激光定位等多种传感器的信号实现无人机的定位与导航方案。该方案应具有障碍物的三维检测功能，获取障碍物在三维地图中的具体位置以及大小信息，实现障碍物的精准避障。对基于无人机的飞机表面喷漆智能检测系统的定位和导航精度进行测试分析，改进和优化设计。基于神经网络的漆面缺陷检测，针对飞机表面喷漆缺陷的规范要求，建立缺陷数据库，开发适用于飞机表面喷漆检测的机器学习模型。设计卷积神经网络的结构，包括卷积、池化，归一化，全连接层的数量和顺序。设计合适的损失函数，用来对卷积网络处理后的特征图进行分类，从而判断任意位置是否存在缺陷，缺陷属于何种类型。开发一套检测软件，该软件集成有机器学习算法、人机交互界面及可视化功能。\n5．基于激光与视觉融合的三维目标检测系统\u0026mdash;与上海市振华重工集团合作  ​\t提供基于相应硬件平台的基于计算机视觉与激光融合的目标检测识别算法，该算法能够完成对应场景内目标物体的实时检测与定位，并给出目标物体的大小，位置等特征信息，并将相关视频及激光数据进行保存以供后续查阅校对。\n6.智能三维巡检无人车 ​ 智能三维巡检无人车通过自主研发的激光与视觉融合的自主定位导航技术、三维建图技术、视频直播技术，能够实现电力、工厂、以及通航机场的全自动、无轨化、智能化、三维化的人员识别、目标识别、行为识别、设备异常监控等巡检任务。通过自主研发的激光与视觉的深度融合，能够实现高精度的定位导航、高精度的三维建图、高精度的三维目标识别、高精度的动态感知。替代人工日常巡检中的繁、难、险和重复性的工作。\n六、团队活动 1.邀请MICCAI Society board member加拿大李硕教授进行学术指导交流 ​ 2019年10月28日，应电子电气工程学院、科研处、智能感知与控制国际联合实验室的共同邀请，加拿大西安大略大学李硕教授来院交流，在现代交通工程中心7950会议室作了主题为“Bring Artifical Intelligence(AI) to Imaging”的学术报告，报告由高永彬老师主持，相关专业教师与研究生出席。李硕教授主要阐述了人工智能(AI)给医学实践带来的重要转变。他表示，AI具有改变疾病诊断和治疗的潜力，可以用来确保患者在正确的时间获得正确的治疗。李教授分享了他在开发创新AI工具和机器学习工具方面的经验，用以应对日常临床医学成像领域的挑战。讲座结束后，李教授悉心为同学们答疑解惑，给大家留下深刻印象。据介绍，李硕，博士，加拿大西安大略大学医学影像和医学生物物理学系副教授，Lawson Health Research Institute科学家。之前，他曾任GeneralElectric（GE）Healthcare的研究科学家和项目经理9年。李教授于2006年创立了伦敦数字影像小组，这是一个充满活力且高度多元化的学科协作小组。李硕教授于2006年从Concordia大学获得计算机科学学位，其博士学位论文获得了工程和计算机科学系的doctoral prize。他发表论文100多篇，曾获得GE、研究所和国际组织的多个奖项；他在该领域的一些著名期刊中担任客座编辑和副编辑，同时在极具影响力的多个会议中担任程序委员会委员。他是Springer六本书的编辑，MICCAI协会的董事会成员。2019年，他的10篇论文被MICCAI收录。他将在2022年医疗影像顶会MICCAI会议上担任大会主席，以及MICCAI society的board member。\n2.邀请中山大学张贺晔教授进行学术指导和交流 ​ 2019年5月7日上午，应电子电气工程学院、科研处、智能感知与控制国际联合实验室的邀请，中山大学张贺晔教授来院交流，做了题为“Computational Modeling and Machine Learning in Medical Image Computing”的学术报告，学院院长方志军、相关专业教师与研究生参加，报告由高永彬老师主持。张教授阐述了通过计算建模及图像处理技术，从心脏影像中提取评估冠心病生理状态的量化指标，并应用于临床诊断的过程。报告结束后，张教授还悉心为同学们答疑解惑，为大家留下了深刻的印象。据介绍，张贺晔教授主要从事健康信息学定量分析研究工作，以临床健康信息需求为驱动，推动并发展了一系列健康信息定量分析的技术与方法。截止目前，发表学术论文78篇（第一或通讯作者41篇），其中SCI检索论文42篇（第一或通讯作者23篇），包括国际顶级期刊MedicalImage Analysis 4篇（通讯作者），国际顶级会议MICCAI 12篇，4篇ESI高被引和一篇ESI热点文章，主持一项NSFC联合基金重点项目和面上项目，申请或授权中国发明专利5项，获吴文俊人工智能科学技术创新奖三等奖（唯一人）。\n3.邀请上海大学施俊教授进行学术指导和交流 ​\t2019年6月6日下午，应电子电气工程学院、科研处、智能感知与控制国际联合实验室的邀请，上海大学施俊教授来校交流，在行政楼506作了题为“面向不同模态医学影像小数据集的深度学习方法研究”的学术报告，报告由高永彬老师主持，师生20余人聆听报告。施俊教授主要阐述了三种医学影像模态所研究的机器学习方法：（1）面向超声成像的肿瘤智能诊断，重点介绍迁移学习方法研究；（2）面向神经影像数据的机器学习方法研究；（3）基于无监督深度学习的病理图像分类。讲座结束后，施俊教授还悉心为同学们答疑解惑，给大家留下深刻印象。据介绍，施俊教授，中国科学技术大学电子工程与信息科学系本硕博连读，2005年获生物医学工程博士学位，读博期间曾任香港理工大学研究助理。主持了国家自然科学基金面上基金项目、青年基金项目等国家级项目，合作主持国家自然科学基金重大科研仪器研制项目、国家自然科学基金重点项目，以及主持上海市自然科学基金项目、科委、教委项目等多项项目。已发表SCI论文四十余篇，包括IEEE TBME、IEEE JBHI、IEEE TNNLS、Pattern Recognition、UMB等期刊，以及高被引论文1篇，授权专利2项。为中国医学装备协会超声装备分会常务委员、中国信息协会医疗卫生和健康产业分会医学人工智能学组常务委员、中国影像AI产学研用创新联盟理事。\n","date":1594346332,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1594346332,"objectID":"695c9dd17480e326bd23b025f4a74edb","permalink":"https://IJLIPC.github.io/zh/project/projects/","publishdate":"2020-07-10T09:58:52+08:00","relpermalink":"/zh/project/projects/","section":"project","summary":"*智能感知与信息处理研究所*","tags":[],"title":"Projects Introduction","type":"project"},{"authors":[],"categories":[],"content":" Zhijun Fang (supervisor),Yongbin Gao, Naixue Xiong, Athanasios V. Vasilakos, Yuming Fang, “A general effective rate control system based on matching measurement and inter-quantizer,” vol. 346-347, pp. 351-368, 2016,Information Sciences. (SCI, IF: 4.832) Yongbin Gao, Hyo Jong Lee, “Local Tiled Deep Networks for Recognition of Vehicle Make and Model,” vol. 16, no. 2, pp. 1-13, Feb. 2016,Sensors. (SCI, IF: 3.03) Yongbin Gao, Hyo Jong Lee, “Cross-Pose Face Recognition Based on Multiple Virtual Views and Alignment Error,” vol. 65, pp. 170-176, Nov. 2015,Pattern Recognition Letters. (SCI, IF: 2.81) Yongbin Gao, Hyo Jong Lee, “Learning warps based similarity for pose-unconstrained face recognition,”Multimedia tools and applications, vol. 77, no. 2, 2018. (SCI, IF: 2.101) Yongbin Gao, Hyo Jong Lee, “Pose-invariant features and Personalized Correspondence Learning for Face Recognition,”Neural Computing and Applications, vol. 31, no.1, pp. 607-616, 2019. (SCI, IF:4.664) Jingming Zhao,Juan Zhang, Zhi Li, Jenq-Neng Hwang,Yongbin Gao, and Zhijun Fang, “DD-CycleGAN: Unpaired image dehazing via Double-Discriminator Cycle-Consistent Generative Adversarial network,” Accepted byEngineering Applications of Artificial Intelligence (EAAI), December 2018. (SCI, IF: 2.819) Renyue Dai,Yongbin Gao , Zhijun Fang, Xiaoyan Jiang, Anjie Wang, Juan Zhang, Cengsi Zhong, “Unsupervised learning of depth estimation based on attention model and global pose optimization,”Signal Processing:Image Communication, 2019. (SCI, IF:2.814) Anjie Wang,Yongbin Gao, Xiaoyan Jiang, Zhijun Fang*, Shanshe Wang, Siwei Ma, Jenq-Neng Hwang. “Unsupervised learning of depth and ego-motion with spatial-temporal geometric constraints,” accepted by IEEE International Conference on Multimedia and Expo (ICME), 2019. (*CCF B*类会议) Chen X, Zhu X. Y.,Wan W.B Yang Z.Y, (2013).Statistics of spatial-temporal concatenations of features at human fixations in action classification. Journal of Vision, 13:520; doi:10.1167/13.9.520. SCI影响因子 3.376. Wan W.B, Yang Z.Y, (2012). Statistics of Three-Dimensional Natural Scene Structure. Journal of Vision ,August 13, 12(9): 1203; doi:10.1167/12.9.1203，SCI影响因子 3.376. Wan W.B, Yang Z.Y, (2012). A Visual Code Book\u0026ndash;Structured Probability Distributions in Natural Scenes. BMC Neuroscience, 13(Suppl 1):P9。 doi:10.1186/1471-2202-13-S1-P9.SCI影响因子 3.04. Po-Han Wu, Chih-Wei Huang, Jenq-Neng Hwang, Jae-Young Pyun,Juan Zhang. Visual Quality Driven Resource Allocation for Real-Time Surveillance Video Uplinking over OFDMA-based Wireless Networks.IEEE Transaction on Vehicular Technology, 2015.64(7): p. 3233 - 3246. WOS:000358239500036 Lei Yu#, Jing Liu, Changsheng Xu*, Label localization by appearance guided graph inferring, 2013*IEEE International Conference on Image Processing (ICIP)*, Melbourne, Australia, 2013.9.15-2013.9.18 (*CCF**推荐*会议) Lei Yu#, Jing Liu, Changsheng Xu*, Label localization with weakly spatial constrained graph propagation, 2013*IEEE International Conference on Multimedia and Expo (ICME),* San Jose, USA, 2013.7.15-2013.7.19(*CCF**推荐*会议) Lei Yu#, Jing Liu, Changsheng Xu*, Descriptive local feature groups for image classification, 2011*IEEE International Conference on Image Processing (ICIP)*, Brussels, Belgium, 2011.9.11-2011.9.14(*CCF**推荐*会议) Lijun Zhang, et al, Obtaining diversity gain for DTV by using MIMO structure in SFN, IEEE Transaction on Broadcasting, 2004.3 Lijun Zhang, et al, A Layer-mixed FEC Scheme for Scalable Media Transmission over Mobile TV Services, IEEE Transaction on Broadcasting, 2017.6  ","date":1594345865,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1594345865,"objectID":"6c2925e079469f20d75038941288fc59","permalink":"https://IJLIPC.github.io/zh/publication/my-article-name/","publishdate":"2020-07-10T09:51:05+08:00","relpermalink":"/zh/publication/my-article-name/","section":"publication","summary":"Zhijun Fang (supervisor),Yongbin Gao, Naixue Xiong, Athanasios V. Vasilakos, Yuming Fang, “A general effective rate control system based on matching measurement and inter-quantizer,” vol. 346-347, pp. 351-368, 2016,Information Sciences. (SCI, IF: 4.","tags":[],"title":"论文发表列表","type":"publication"},{"authors":[],"categories":[],"content":"欢迎到访智能感知与控制国际联合实验室 ","date":1594301870,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1594301870,"objectID":"2550a6b6b1e3ef22f904f2d225585395","permalink":"https://IJLIPC.github.io/zh/post/my-article-name/","publishdate":"2020-07-09T21:37:50+08:00","relpermalink":"/zh/post/my-article-name/","section":"post","summary":"欢迎到访智能感知与控制国际联合实验室 ","tags":[],"title":"Welcome","type":"post"}]